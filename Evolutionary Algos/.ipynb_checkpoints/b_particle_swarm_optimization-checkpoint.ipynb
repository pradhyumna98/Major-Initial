{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random,math,copy,timeit\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy as dc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(n,dim):\n",
    "    gens=[[0 for g in range(dim)] for _ in range(n)]\n",
    "    for i,gen in enumerate(gens) :\n",
    "        r=random.randint(1,dim)\n",
    "        for _r in range(r):\n",
    "            gen[_r]=1\n",
    "        random.shuffle(gen)\n",
    "    return gens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_d,train_l,gen):\n",
    "        mask=np.array(gen) > 0\n",
    "        al_data=np.array([al[mask] for al in train_d])\n",
    "        kf = ms.KFold(n_splits=4)\n",
    "        s = 0\n",
    "        for tr_ix,te_ix in kf.split(al_data):\n",
    "            s+= RandomForestClassifier(n_estimators=25).fit(al_data[tr_ix],train_l[tr_ix]).score(al_data[te_ix],train_l[te_ix])#.predict(al_test_data)\n",
    "        s/=4\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsig(n): return 1 / (1 + math.exp(-n))\n",
    "def sign(x): return 1 if x > 0 else (-1 if x!=0 else 0)\n",
    "\n",
    "def BPSO(train_d,train_l,n=20,max_iter=200,w1=0.5,c1=0.5,c2=0.5,vmax=4):\n",
    "    \"\"\"\n",
    "    input:{ \n",
    "            Eval_Func: Evaluate_Function, type is class\n",
    "            n: Number of population, default=20\n",
    "            max_iter: Number of max iteration, default=300\n",
    "            dim: Number of feature, default=None\n",
    "            prog: Do you want to use a progress bar?, default=False\n",
    "            w1: move rate, default=0.5\n",
    "            c1,c2: It's are two fixed variables, default=1,1\n",
    "            vmax: Limit search range of vmax, default=4\n",
    "            }\n",
    "    output:{\n",
    "            Best position: type list(int) [1,0,0,1,.....]\n",
    "            Nunber of 1s in best position: type int [0,1,1,0,1] â†’ 3\n",
    "            }\n",
    "    \"\"\"\n",
    "    dim=len(train_d[0])\n",
    "    personal_best=float(\"-inf\")\n",
    "    global_best=float(\"-inf\")\n",
    "    gens=random_search(n,dim)\n",
    "    vel=[[random.random()-0.5 for d in range(dim)] for _n in range(n)]\n",
    "    one_vel=[[random.random()-0.5 for d in range(dim)] for _n in range(n)]\n",
    "    zero_vel=[[random.random()-0.5 for d in range(dim)] for _n in range(n)]\n",
    "    fit=[float(\"-inf\") for i in range(n)]\n",
    "    personal_best=dc(fit)\n",
    "    xpersonal_best=dc(gens)\n",
    "    global_best=max(fit)\n",
    "    xglobal_best=gens[fit.index(max(fit))]\n",
    "    gens_dict={tuple([0]*dim):float(\"-inf\")}\n",
    "    for it in range(max_iter):\n",
    "        for i in range(n):\n",
    "            if tuple(gens[i]) in gens_dict:\n",
    "                score=gens_dict[tuple(gens[i])]\n",
    "            else:\n",
    "                score=evaluate(train_d,train_l,gens[i])\n",
    "                gens_dict[tuple(gens[i])]=score\n",
    "            fit[i]=score\n",
    "            if fit[i]>personal_best[i]:#max\n",
    "                personal_best[i]=dc(fit[i])\n",
    "                xpersonal_best[i]=dc(gens[i])\n",
    "        gg=max(fit)\n",
    "        xgg=gens[fit.index(gg)]\n",
    "        if global_best<gg:#max\n",
    "            global_best=dc(gg)\n",
    "            xglobal_best=dc(xgg)\n",
    "        oneadd=[[0 for d in range(dim)] for i in range(n)]\n",
    "        zeroadd=[[0 for d in range(dim)] for i in range(n)]\n",
    "        c3=c1*random.random()\n",
    "        dd3=c2*random.random()\n",
    "        for i in range(n):\n",
    "            for j in range(dim):\n",
    "                if xpersonal_best[i][j]==0:\n",
    "                    oneadd[i][j]=oneadd[i][j]-c3\n",
    "                    zeroadd[i][j]=zeroadd[i][j]+c3\n",
    "                else:\n",
    "                    oneadd[i][j]=oneadd[i][j]+c3\n",
    "                    zeroadd[i][j]=zeroadd[i][j]-c3\n",
    "                if xglobal_best[j]==0:\n",
    "                    oneadd[i][j]=oneadd[i][j]-dd3\n",
    "                    zeroadd[i][j]=zeroadd[i][j]+dd3\n",
    "                else:\n",
    "                    oneadd[i][j]=oneadd[i][j]+dd3\n",
    "                    zeroadd[i][j]=zeroadd[i][j]-dd3\n",
    "        one_vel=[[w1*_v+_a for _v,_a in zip(ov,oa)] for ov,oa in zip(one_vel,oneadd)]\n",
    "        zero_vel=[[w1*_v+_a for _v,_a in zip(ov,oa)] for ov,oa in zip(zero_vel,zeroadd)]\n",
    "        for i in range(n):\n",
    "            for j in range(dim):\n",
    "                if abs(vel[i][j]) > vmax:\n",
    "                    zero_vel[i][j]=vmax*sign(zero_vel[i][j])\n",
    "                    one_vel[i][j]=vmax*sign(one_vel[i][j])\n",
    "        for i in range(n):\n",
    "            for j in range(dim):\n",
    "                if gens[i][j]==1:\n",
    "                    vel[i][j]=zero_vel[i][j]\n",
    "                else:\n",
    "                    vel[i][j]=one_vel[i][j]\n",
    "        veln=[[logsig(s[_s]) for _s in range(len(s))] for s in vel]\n",
    "        temp=[[random.random() for d in range(dim)] for _n in range(n)]\n",
    "        for i in range(n):\n",
    "            for j in range(dim):\n",
    "                if temp[i][j]<veln[i][j]:\n",
    "                    gens[i][j]= 0 if gens[i][j] ==1 else 1\n",
    "                else:\n",
    "                    pass\n",
    "    return xglobal_best,xglobal_best.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(gen,tr_x,tr_y,te_x,te_y):\n",
    "    mask=np.array(gen) == 1\n",
    "    al_data=np.array(tr_x[:,mask])\n",
    "    al_test_data=np.array(te_x[:,mask])\n",
    "    return np.mean([RandomForestClassifier(n_estimators=25).fit(al_data,tr_y).score(al_test_data,te_y) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shubbham28/Downloads/Arrhythmia/heart.csv\") as f:\n",
    "    x=np.array([[float(d) for d  in data.split(',')] for data in f.read().splitlines()])\n",
    "with open(\"/home/shubbham28/Downloads/Arrhythmia/heart_output.csv\") as f:\n",
    "    y=np.array([float(data) for data in f.read().splitlines()])\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y)\n",
    "train_d, test_d, train_l, test_l = train_test_split(x, training_scores_encoded, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7588235294117647\n",
      "1  1111000010111  8  0.767647\n",
      "2  1110001010111  8  0.752941\n",
      "3  0111010011111  9  0.794118\n",
      "4  1111100010111  9  0.802941\n",
      "5  1110001010110  7  0.720588\n",
      "6  1110001010111  8  0.764706\n",
      "7  1110000011110  7  0.758824\n",
      "8  1110011000111  8  0.779412\n",
      "9  1110011010110  8  0.717647\n",
      "10  0110101010111  8  0.817647\n",
      "11  1110001010110  7  0.702941\n",
      "12  1111011001111  10  0.782353\n",
      "13  1010010011111  8  0.800000\n",
      "14  1110011010111  9  0.761765\n",
      "15  1110010010111  8  0.770588\n",
      "16  0010101011111  8  0.797059\n",
      "17  1110011011110  9  0.779412\n",
      "18  1110011010111  9  0.758824\n",
      "19  1110001010110  7  0.702941\n",
      "20  1110011010110  8  0.723529\n",
      "[17, 18, 20, 4, 3, 10, 14, 0, 18, 6, 20, 20, 13] 8\n",
      "[11 10  2  8  1  0  6 12]\n",
      "Final:   1110001010111   8   0.762794    9639.5083\n"
     ]
    }
   ],
   "source": [
    "k=[1 for r in range(len(x[0]))]\n",
    "print test_score(k,train_d,train_l,test_d,test_l)\n",
    "fattr=0\n",
    "ftest=0.0\n",
    "flist=[0 for r in range(len(x[0]))]\n",
    "final_list=[0 for r in range(len(x[0]))]\n",
    "start=timeit.default_timer()\n",
    "for i in range(20):\n",
    "    g,l=BPSO(train_d,train_l,n=20,max_iter=200,w1=0.5,c1=0.5,c2=0.5,vmax=4)\n",
    "    fattr+=l\n",
    "    test=test_score(g,train_d,train_l,test_d,test_l)\n",
    "    ftest+=test\n",
    "    for j in range(len(flist)):\n",
    "        if g[j]==1:\n",
    "            flist[j]+=1\n",
    "    print(\"{0}  {1}  {2}  {3:.6f}\".format(i+1,\"\".join(map(str,g)),l,test))\n",
    "fattr=fattr/20\n",
    "ftest=ftest/20\n",
    "end=timeit.default_timer()\n",
    "time=end-start\n",
    "print flist,fattr\n",
    "final=np.argsort(flist)[::-1][:fattr]\n",
    "print final\n",
    "for i in range(len(final)):\n",
    "    final_list[final[i]]=1\n",
    "print(\"{0}  {1}   {2}   {3:.6f}    {4:.4f}\".format(\"Final: \",\"\".join(map(str,final_list)),fattr,ftest,time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
